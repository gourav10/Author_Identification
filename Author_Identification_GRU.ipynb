{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e0ab02-5934-4575-86ba-6dea668bb9c2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31d17ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa2af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de5d084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision, torch\n",
    "from torchvision import transforms as T\n",
    "from torch import optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66996678-9262-4278-a840-3fb2b8cc6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf84063-58b2-4c88-a70d-e4d652553ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff40ab3-75ad-4284-8c61-480b1cef0519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9061027c",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b58a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/ht_13/OneDrive/Documents/6140-ML/Project/'\n",
    "# load test result file\n",
    "test_author = sio.loadmat(path+'dataset/dataset/test_author.mat')[\"test_author\"]\n",
    "# load train dataFrame\n",
    "train_df = pd.read_csv(path+'dataset/dataset/Gungor_2018_VictorianAuthorAttribution_data-train.csv',encoding = \"ISO-8859-1\")\n",
    "# load train dataFrame\n",
    "test_df = pd.read_csv(path+'dataset/dataset/Gungor_2018_VictorianAuthorAttribution_data.csv',encoding = \"ISO-8859-1\")\n",
    "# load list of authors\n",
    "f = open('author_list.txt', 'r')\n",
    "author_list = f.read().split('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78486d51-76f1-4bd8-8217-2b832c14b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['author'] = test_author.reshape((test_df.shape[0]))\n",
    "missing_authors = [5, 7, 31, 47, 49]\n",
    "test_df = test_df.loc[~(test_df['author'].isin(missing_authors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c44e50d-508f-4da9-9909-124979113754",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['author'] = test_df['author']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81f944e-3a64-42f8-990e-a2e4fa1012b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nt it seems te me how much money is he worth a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to talk about why you heard of such a case as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my foot on the ground and said i believe you d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hour or wait for miss oh wait for by all means...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will not listen to such words now go and remem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  nt it seems te me how much money is he worth a...       0\n",
       "1  to talk about why you heard of such a case as ...       0\n",
       "2  my foot on the ground and said i believe you d...       0\n",
       "3  hour or wait for miss oh wait for by all means...       0\n",
       "4  will not listen to such words now go and remem...       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d264021",
   "metadata": {},
   "source": [
    "#### Get Authors Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d3ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list_path='./dataset/author_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d670b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['author'] = train_df['author']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c01adc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ou have time to listen i will give you the ent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish for solitude he was twenty years of age a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and the skirt blew in perfect freedom about th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of san and the rows of shops opposite impresse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an hour s walk was as tiresome as three in a s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author\n",
       "0  ou have time to listen i will give you the ent...       0\n",
       "1  wish for solitude he was twenty years of age a...       0\n",
       "2  and the skirt blew in perfect freedom about th...       0\n",
       "3  of san and the rows of shops opposite impresse...       0\n",
       "4  an hour s walk was as tiresome as three in a s...       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8c0ad7",
   "metadata": {},
   "source": [
    "### Split the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8e1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373007a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set = train_test_split(train_df ,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd20bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42942, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "103b4e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10736, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1c66906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15593b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set['text'] = train_set['text'].progress_apply(lambda x:\" \".join(word_tokenize(x)))\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "850f96b0-b9fc-464b-ae57-82b69abceacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25636/25636 [00:45<00:00, 565.03it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['text'] = test_df['text'].progress_apply(lambda x:\" \".join(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "506bb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['text_length'] = train_set['text'].progress_apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d49b4c8-3c9d-42ff-a48d-2c19301ad838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 25636/25636 [00:00<00:00, 32094.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['text_length'] = test_df['text'].progress_apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "163619c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nt it seems te me how much money is he worth a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to talk about why you heard of such a case as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my foot on the ground and said i believe you d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hour or wait for miss oh wait for by all means...</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will not listen to such words now go and remem...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author  text_length\n",
       "0  nt it seems te me how much money is he worth a...       0         1001\n",
       "1  to talk about why you heard of such a case as ...       0         1000\n",
       "2  my foot on the ground and said i believe you d...       0         1000\n",
       "3  hour or wait for miss oh wait for by all means...       0         1001\n",
       "4  will not listen to such words now go and remem...       0         1000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980233a5-db5c-4c19-b4cd-ef0f728dce0e",
   "metadata": {},
   "source": [
    "## Prepare Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cddc0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = test_df['text_length'].max()\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "610ab326-048d-4b27-a839-3cf7b58e207e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n"
     ]
    }
   ],
   "source": [
    "print(MAX_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2be3e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dictionary = {}\n",
    "with open('C:/Users/ht_13/Downloads/Authorship_Attribution-master/Authorship_Attribution-master/glove.6B.100d.txt','r',encoding=\"utf8\") as glove_file:\n",
    "    for line in glove_file:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embedding_dictionary[word]=vectors\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7db56e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Embedding Matrix\n",
    "def generate_word_embeddings(text):\n",
    "    embedding_matrix = torch.zeros((1008, 100))\n",
    "    for idx, word in enumerate(text.split(\" \")):\n",
    "        if(idx>1007):\n",
    "            break\n",
    "        if(word in embedding_dictionary):\n",
    "            embedding_vector = torch.from_numpy(embedding_dictionary.get(word))\n",
    "            if(embedding_vector is not None):\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d47ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['embeddings'] = train_set['text'].progress_apply(lambda x:generate_word_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c30b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_pickle('auth_id_train_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08d01b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10736/10736 [00:48<00:00, 220.81it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_set['embeddings'] = valid_set['text'].progress_apply(lambda x:generate_word_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "384117da",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set.to_pickle('auth_id_valid_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96183e3d-4286-4b38-969e-47aebf281fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25636/25636 [01:48<00:00, 235.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['embeddings'] = test_df['text'].progress_apply(lambda x:generate_word_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6a426-cccc-47e3-bde4-b69ae916d27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df.to_pickle('auth_id_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78351196-855a-4ded-ae5f-e2ffcd31f6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>text_length</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nt it seems te me how much money is he worth a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>[[tensor(0.3181), tensor(1.0088), tensor(-0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to talk about why you heard of such a case as ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>[[tensor(-0.1897), tensor(0.0500), tensor(0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my foot on the ground and said i believe you d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>[[tensor(0.0803), tensor(-0.1086), tensor(0.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hour or wait for miss oh wait for by all means...</td>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>[[tensor(-0.3571), tensor(-0.2348), tensor(0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will not listen to such words now go and remem...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>[[tensor(-0.2670), tensor(0.4491), tensor(0.55...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  author  text_length  \\\n",
       "0  nt it seems te me how much money is he worth a...       0         1001   \n",
       "1  to talk about why you heard of such a case as ...       0         1000   \n",
       "2  my foot on the ground and said i believe you d...       0         1000   \n",
       "3  hour or wait for miss oh wait for by all means...       0         1001   \n",
       "4  will not listen to such words now go and remem...       0         1000   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [[tensor(0.3181), tensor(1.0088), tensor(-0.26...  \n",
       "1  [[tensor(-0.1897), tensor(0.0500), tensor(0.19...  \n",
       "2  [[tensor(0.0803), tensor(-0.1086), tensor(0.72...  \n",
       "3  [[tensor(-0.3571), tensor(-0.2348), tensor(0.0...  \n",
       "4  [[tensor(-0.2670), tensor(0.4491), tensor(0.55...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ca581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bdbb79-ca5f-44f5-87ca-a386cd5a8473",
   "metadata": {},
   "source": [
    "## Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e532eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,num_layers,out_dim):\n",
    "        super(GRU,self).__init__()\n",
    "        \n",
    "        #Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #Number of Hidden Layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        #Building LSTM\n",
    "        self.gru = nn.GRU(input_dim,hidden_dim,num_layers, batch_first = True)\n",
    "        self.sequential = nn.Sequential(nn.Linear(hidden_dim, 2*hidden_dim),nn.ReLU(),nn.Linear(2*hidden_dim, hidden_dim),nn.ReLU())\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out, hn = self.gru(x)\n",
    "        out = self.sequential(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bde133-296f-49d3-9e54-68fd7944041f",
   "metadata": {},
   "source": [
    "# Build Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76126cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,dataframe):\n",
    "        embeddings = dataframe['embeddings'].values\n",
    "        authors = dataframe['author'].values\n",
    "        \n",
    "        self.x = embeddings\n",
    "        self.y = torch.tensor(authors)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc20084-fe75-4a01-861e-157c1e0fa544",
   "metadata": {},
   "source": [
    "#### Load the Saved Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619f0c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 19s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%time train_set = pd.read_pickle(\"pickle/auth_id_train_df.pkl\")\n",
    "%time valid_set = pd.read_pickle(\"pickle/auth_id_valid_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f367220-bde2-4fd0-9d8e-036ba4824715",
   "metadata": {},
   "source": [
    "# Generate Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71ab792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AuthorTextDataset(train_set)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=128,shuffle=False)\n",
    "\n",
    "validation_dataset = AuthorTextDataset(valid_set)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset,batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f2868eb-7e30-4757-8258-c330c3de57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AuthorTextDataset(test_df)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58087a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "#     return torch.device(\"cpu\")\n",
    "    if(torch.cuda.is_available()):\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13811433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99296d-24b7-4ad7-b768-807672e4d002",
   "metadata": {},
   "source": [
    "# Training and Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d088872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data_loader, optimizer, criterion, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for batch_idx, (feature_data,labels) in tqdm(enumerate(data_loader)):\n",
    "        feature_data = feature_data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(feature_data)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        total += labels.size(0)        \n",
    "        train_loss += loss.item()\n",
    "        num_batches+=1\n",
    "        \n",
    "    train_acc = 100 * correct / total\n",
    "    return train_loss/num_batches,train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02a2eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,data_loader, optimizer, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    num_batches = 0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    for batch_idx,(feature_data,labels) in tqdm(enumerate(data_loader)):\n",
    "        feature_data = feature_data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(feature_data)\n",
    "        loss = criterion(output,labels)\n",
    "        _,predicted = torch.max(output.data,1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        total += labels.size(0)\n",
    "        val_loss += loss.item()\n",
    "        num_batches+=1\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss/num_batches,val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a22173-3181-45fc-bea9-f9bc754f4531",
   "metadata": {},
   "source": [
    "#### Training and Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e69a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,num_epochs,train_dl,validation_dl):\n",
    "    test_losses=[]\n",
    "    test_accuracies = []\n",
    "    train_losses=[]\n",
    "    train_accuracies=[]\n",
    "    \n",
    "    max_accuracy = -float('inf')\n",
    "    best_model = model\n",
    "    learn_rate = 0.01\n",
    "    \n",
    "    device = get_device()\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model,train_dl, optimizer, criterion, device)\n",
    "        test_loss, test_acc = validate(model,validation_dl, optimizer, criterion, device)\n",
    "        \n",
    "        if(epoch%1==0):\n",
    "            print(\"Epoch:{}, Train Loss: {:.4f}, Train Accuracy: {:.4f}, Valid Loss: {:.4f}, Valid Accuracy: {:.4f}\"\n",
    "                  .format(epoch,train_loss,train_acc,test_loss,test_acc))\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "        if(test_acc>max_accuracy):\n",
    "            best_model = copy.deepcopy(model)\n",
    "            max_accuracy = test_acc\n",
    "            print(\"Saving Best Model with Accuracy: \", max_accuracy)\n",
    "    \n",
    "    plot_loss(num_epochs,train_losses,test_losses)\n",
    "    return best_model,max_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f30b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(num_epochs,train_losses,test_losses):\n",
    "    \n",
    "    # Using Numpy to create an array X\n",
    "    X = range(num_epochs)\n",
    "    \n",
    "    # Assign variables to the y axis part of the curve\n",
    "    y = train_losses\n",
    "    z = test_losses\n",
    "    \n",
    "    plt.plot(X,y,color='blue')\n",
    "    plt.plot(X,z,color='red')\n",
    "    plt.legend(['Train Loss','Validation Loss'],loc='upper right')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(\"Training and Validation Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dacd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model,data,device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    num_batches = 0\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    for batch_idx,(feature_data,labels) in enumerate(data):\n",
    "        feature_data = feature_data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(feature_data)\n",
    "        loss = criterion(output,labels)\n",
    "        total += labels.size(0)\n",
    "        val_loss += loss.item()\n",
    "        num_batches+=1\n",
    "    return val_loss/num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd33c5-275e-4070-825a-d6180ade03c0",
   "metadata": {},
   "source": [
    "# Model Initialization and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85faae9-341c-4170-b729-5a58c4e00915",
   "metadata": {},
   "source": [
    "#### GRU with 128 hidden neurons and 2 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f35c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (gru): GRU(100, 128, num_layers=2, batch_first=True)\n",
      "  (sequential): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=50, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = 100 #10 previous stock values\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 50\n",
    "\n",
    "random_seed = 2\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim,out_dim=output_dim, num_layers=num_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c16598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:24,  1.27it/s]\n",
      "84it [00:26,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Train Loss: 3.0523, Train Accuracy: 20.4043, Valid Loss: 2.4491, Valid Accuracy: 32.0417\n",
      "Saving Best Model with Accuracy:  tensor(32.0417, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:16,  1.31it/s]\n",
      "84it [00:22,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Train Loss: 2.1246, Train Accuracy: 40.8551, Valid Loss: 1.9072, Valid Accuracy: 46.8331\n",
      "Saving Best Model with Accuracy:  tensor(46.8331, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:14,  1.32it/s]\n",
      "84it [00:22,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Train Loss: 1.6312, Train Accuracy: 54.3570, Valid Loss: 1.6156, Valid Accuracy: 55.0484\n",
      "Saving Best Model with Accuracy:  tensor(55.0484, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:13,  1.32it/s]\n",
      "84it [00:22,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Train Loss: 1.3674, Train Accuracy: 61.9603, Valid Loss: 1.3902, Valid Accuracy: 61.7176\n",
      "Saving Best Model with Accuracy:  tensor(61.7176, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4, Train Loss: 1.1660, Train Accuracy: 67.6960, Valid Loss: 1.2867, Valid Accuracy: 65.9370\n",
      "Saving Best Model with Accuracy:  tensor(65.9370, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:5, Train Loss: 1.0534, Train Accuracy: 70.6907, Valid Loss: 1.1455, Valid Accuracy: 70.0261\n",
      "Saving Best Model with Accuracy:  tensor(70.0261, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:6, Train Loss: 0.9377, Train Accuracy: 74.2304, Valid Loss: 1.1841, Valid Accuracy: 69.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:7, Train Loss: 0.8585, Train Accuracy: 76.2633, Valid Loss: 1.0985, Valid Accuracy: 72.3174\n",
      "Saving Best Model with Accuracy:  tensor(72.3174, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:8, Train Loss: 0.8140, Train Accuracy: 77.6303, Valid Loss: 1.0691, Valid Accuracy: 72.7645\n",
      "Saving Best Model with Accuracy:  tensor(72.7645, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:21,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:9, Train Loss: 0.7715, Train Accuracy: 78.8296, Valid Loss: 1.0076, Valid Accuracy: 74.4318\n",
      "Saving Best Model with Accuracy:  tensor(74.4318, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:23,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10, Train Loss: 0.7371, Train Accuracy: 79.6050, Valid Loss: 0.9816, Valid Accuracy: 74.7578\n",
      "Saving Best Model with Accuracy:  tensor(74.7578, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:14,  1.32it/s]\n",
      "84it [00:22,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:11, Train Loss: 0.7052, Train Accuracy: 80.6320, Valid Loss: 1.0066, Valid Accuracy: 74.8323\n",
      "Saving Best Model with Accuracy:  tensor(74.8323, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:12, Train Loss: 0.6974, Train Accuracy: 80.8113, Valid Loss: 0.9655, Valid Accuracy: 75.8476\n",
      "Saving Best Model with Accuracy:  tensor(75.8476, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:13, Train Loss: 0.6909, Train Accuracy: 80.9138, Valid Loss: 0.9517, Valid Accuracy: 75.8662\n",
      "Saving Best Model with Accuracy:  tensor(75.8662, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:10,  1.34it/s]\n",
      "84it [00:22,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:14, Train Loss: 0.6555, Train Accuracy: 82.1969, Valid Loss: 0.9320, Valid Accuracy: 76.9560\n",
      "Saving Best Model with Accuracy:  tensor(76.9560, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:15, Train Loss: 0.6290, Train Accuracy: 82.5695, Valid Loss: 0.9260, Valid Accuracy: 76.8722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16, Train Loss: 0.6179, Train Accuracy: 82.9724, Valid Loss: 0.9154, Valid Accuracy: 77.8595\n",
      "Saving Best Model with Accuracy:  tensor(77.8595, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:17, Train Loss: 0.5995, Train Accuracy: 83.4800, Valid Loss: 0.9168, Valid Accuracy: 77.5149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:18, Train Loss: 0.6086, Train Accuracy: 83.2006, Valid Loss: 0.9447, Valid Accuracy: 77.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:10,  1.34it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:19, Train Loss: 0.5913, Train Accuracy: 83.7292, Valid Loss: 0.9679, Valid Accuracy: 76.3320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:20, Train Loss: 0.5797, Train Accuracy: 84.0855, Valid Loss: 0.9823, Valid Accuracy: 76.2202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:10,  1.34it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:21, Train Loss: 0.6128, Train Accuracy: 83.3846, Valid Loss: 0.9271, Valid Accuracy: 76.8256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:22, Train Loss: 0.6241, Train Accuracy: 83.0981, Valid Loss: 0.9937, Valid Accuracy: 76.4158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:13,  1.33it/s]\n",
      "84it [00:22,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23, Train Loss: 0.5847, Train Accuracy: 83.9015, Valid Loss: 0.8960, Valid Accuracy: 78.3718\n",
      "Saving Best Model with Accuracy:  tensor(78.3718, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:24, Train Loss: 0.5400, Train Accuracy: 85.0636, Valid Loss: 0.9179, Valid Accuracy: 78.0458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25, Train Loss: 0.5665, Train Accuracy: 84.4814, Valid Loss: 0.9293, Valid Accuracy: 77.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:26, Train Loss: 0.6085, Train Accuracy: 83.5033, Valid Loss: 0.8619, Valid Accuracy: 78.8841\n",
      "Saving Best Model with Accuracy:  tensor(78.8841, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:27, Train Loss: 0.5611, Train Accuracy: 84.6747, Valid Loss: 0.8822, Valid Accuracy: 78.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:28, Train Loss: 0.5116, Train Accuracy: 85.9112, Valid Loss: 0.8914, Valid Accuracy: 79.3964\n",
      "Saving Best Model with Accuracy:  tensor(79.3964, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:29, Train Loss: 0.5227, Train Accuracy: 85.7110, Valid Loss: 0.9032, Valid Accuracy: 78.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:30, Train Loss: 0.5391, Train Accuracy: 85.3151, Valid Loss: 0.9638, Valid Accuracy: 77.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:13,  1.33it/s]\n",
      "84it [00:22,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31, Train Loss: 0.7820, Train Accuracy: 79.2627, Valid Loss: 1.1554, Valid Accuracy: 71.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:21,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:32, Train Loss: 0.7960, Train Accuracy: 78.8296, Valid Loss: 1.0555, Valid Accuracy: 73.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:33, Train Loss: 0.6655, Train Accuracy: 82.1340, Valid Loss: 0.9415, Valid Accuracy: 77.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34, Train Loss: 0.5900, Train Accuracy: 84.1600, Valid Loss: 0.9276, Valid Accuracy: 76.7977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:35, Train Loss: 0.5492, Train Accuracy: 84.9867, Valid Loss: 1.0614, Valid Accuracy: 75.7452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:36, Train Loss: 0.5732, Train Accuracy: 84.4977, Valid Loss: 0.9041, Valid Accuracy: 78.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:37, Train Loss: 0.5525, Train Accuracy: 85.0799, Valid Loss: 0.8971, Valid Accuracy: 78.4277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:38, Train Loss: 0.5060, Train Accuracy: 86.1255, Valid Loss: 0.8619, Valid Accuracy: 79.8621\n",
      "Saving Best Model with Accuracy:  tensor(79.8621, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:39, Train Loss: 0.4867, Train Accuracy: 86.6681, Valid Loss: 0.8585, Valid Accuracy: 79.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:40, Train Loss: 0.4748, Train Accuracy: 87.0570, Valid Loss: 0.9103, Valid Accuracy: 78.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:41, Train Loss: 0.5396, Train Accuracy: 85.3803, Valid Loss: 1.0000, Valid Accuracy: 76.5183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:42, Train Loss: 0.6997, Train Accuracy: 81.7498, Valid Loss: 2.9578, Valid Accuracy: 26.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.34it/s]\n",
      "84it [00:22,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:43, Train Loss: 3.1123, Train Accuracy: 20.7047, Valid Loss: 3.3943, Valid Accuracy: 13.3756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:44, Train Loss: 3.2615, Train Accuracy: 15.6863, Valid Loss: 3.1227, Valid Accuracy: 18.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:13,  1.33it/s]\n",
      "84it [00:22,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:45, Train Loss: 3.0332, Train Accuracy: 20.5999, Valid Loss: 2.9855, Valid Accuracy: 21.4512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:46, Train Loss: 2.9139, Train Accuracy: 23.2360, Valid Loss: 2.9060, Valid Accuracy: 23.2675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:11,  1.33it/s]\n",
      "84it [00:22,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:47, Train Loss: 2.8313, Train Accuracy: 25.3807, Valid Loss: 2.8337, Valid Accuracy: 25.3539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:12,  1.33it/s]\n",
      "84it [00:22,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:48, Train Loss: 2.7604, Train Accuracy: 26.7617, Valid Loss: 2.7676, Valid Accuracy: 26.7791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [04:13,  1.33it/s]\n",
      "84it [00:22,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:49, Train Loss: 2.7043, Train Accuracy: 27.7421, Valid Loss: 2.7622, Valid Accuracy: 26.4531\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA//0lEQVR4nO3dd3wUdfrA8c+TEHonUXpTRKmhCKKICIqKBcSKqCAqggU9G3p66Ol5eHe2w4aoWE4FsSFiR0Xwp6KAtIgI0qXXEEICJM/vj++EbMJusimbTTLP+/Wa1+7OzM5+Z7OZZ75dVBVjjDH+FRPtBBhjjIkuCwTGGONzFgiMMcbnLBAYY4zPWSAwxhifs0BgjDE+Z4HAFIiIfCoiQ4t732gSkTUickYEjjtLRK7zng8RkS/C2bcQn9NURFJEJLawaTX+ZoHAB7yLRNaSKSL7A14PKcixVPUcVX2tuPctjUTkXhGZHWR9vIgcEJF24R5LVd9U1X7FlK4cgUtV16lqdVXNKI7j5/osFZFji/u4pnSxQOAD3kWiuqpWB9YB5wesezNrPxGpEL1Ulkr/A04WkRa51l8OLFHVpVFIkzHFzgKBj4lIbxHZICJjRGQz8IqI1BGRGSKyTUR2ec8bB7wnsLhjmIh8JyKPefuuFpFzCrlvCxGZLSJ7RWSmiDwrIm+ESHc4aXxYRP7PO94XIhIfsP0qEVkrIjtE5L5Q34+qbgC+Bq7Ktelq4LX80pErzcNE5LuA12eKyG8iskdEngEkYNsxIvK1l77tIvKmiNT2tv0PaAp85OXo7haR5t6dewVvn4YiMl1EdorIShG5PuDYD4rIVBF53ftukkSka6jvIBQRqeUdY5v3Xd4vIjHetmNF5Fvv3LaLyNveehGRJ0Vkq7dtcVauSkQqeb+NdSKyRUQmiEgVb1u8993u9s5pTtZnmeJhX6apD9QFmgEjcL+JV7zXTYH9wDN5vL87sByIB/4NvCwiUoh93wJ+AuoBD3LkxTdQOGm8ArgGOAqoCNwJICJtgOe94zf0Pi/oxdvzWmBaRKQ1kAhMDjMdR/CC0nvA/bjv4g/glMBdgHFe+k4AmuC+E1T1KnLm6v4d5CMmAxu8918M/FNE+gZsvwCYAtQGpoeT5iCeBmoBLYHTcMHxGm/bw8AXQB3cd/u0t74f0As4zvvsy4Ad3rZ/eesTgWOBRsBYb9sd3vkkAEcDfwVsbJzipKq2+GgB1gBneM97AweAynnsnwjsCng9C7jOez4MWBmwrSruH7R+QfbFXUQPAVUDtr8BvBHmOQVL4/0Br28EPvOejwWmBGyr5n0HZ4Q4dlUgGTjZe/0I8GEhv6vvvOdXAz8G7Ce4C911IY47EPgl2N/Qe93c+y4r4IJGBlAjYPs44FXv+YPAzIBtbYD9eXy3Chyba10skA60CVh3AzDLe/46MBFonOt9fYDfgZOAmFznvw84JmBdD2C19/wh4MPc6bCl+BbLEZhtqpqW9UJEqorIC152PxmYDdSW0C1SNmc9UdVU72n1Au7bENgZsA5gfagEh5nGzQHPUwPS1DDw2Kq6j+y70iN4aXoHuNrLvQzB5RIK811lyZ0GDXwtIkeJyBQR+dM77hu4nEM4sr7LvQHr1uLusLPk/m4qS8Hqh+Jxuay1IT7jbtzF/Sev6Gk4gKp+jct9PAtsEZGJIlITd6dfFZjvFf/sBj7z1gP8B1gJfCEiq0TkngKk1YTBAoHJncW+A2gNdFfVmrisPASUYUfAJqCuiFQNWNckj/2LksZNgcf2PrNePu95DbgUOBOoAcwoYjpyp0HIeb7jcH+XDt5xr8x1zLyKRTbivssaAeuaAn/mk6aC2A4cxBWJHfEZqrpZVa9X1Ya4nMJz4rU8UtXxqtoFaIsrCrrLO95+oK2q1vaWWuoaN6Cqe1X1DlVtCZwP3J6rqMsUkQUCk1sN3D/lbhGpCzwQ6Q9U1bXAPOBBEakoIj1w//CRSOO7wHki0lNEKuKKHfL7P5gD7MYVd0xR1QNFTMfHQFsRGeTdiY/GFZFlqQGkeMdthLtYBtqCK5s/gqquB74HxolIZRHpAFwLvBls/zBV9I5VWUQqe+umAo+ISA0RaQbcjsu5ICKXSHal+S5c4MoQkRNFpLuIxOGKgtKADFXNBF4EnhSRo7xjNBKRs7zn53kV0IIrpsvwFlNMLBCY3J4CquDu0n7EZdFLwhBcufAO4B/A27hy6GCeopBpVNUk4CZc5fQm3IVqQz7vUVy5dzPvsUjpUNXtwCXAo7jzbQX8X8Aufwc6A3twQeP9XIcYB9zvFaPcGeQjBuPqDTYCHwAPqOqX4aQthCRcwMtargFuwV3MVwHf4b7PSd7+JwJzRSQFVxl9q6quBmriLvi7cEVJO4DHvPeMwRX//OgVh83E5bbAfT8zccHxB+A5VZ1VhPMxuYhXGWNMqeI1OfxNVSOeIzHG7yxHYEoFr9jgGBGJEZGzgQHAtCgnyxhfsJ6kprSojysCqYcrqhmlqr9EN0nG+IMVDRljjM9Z0ZAxxvhcxIqGvGZms4FK3ue8m7viT0R643oMrvZWva+qD+V13Pj4eG3evHlxJ9cYY8q1+fPnb1fVhGDbIllHkA70UdUUr93wdyLyqar+mGu/Oap6XrgHbd68OfPmzSvWhBpjTHknImtDbYtYIPDaXqd4L+O8xSokjDGmlIloHYGIxIrIQmAr8KWqzg2yWw8RWSRuNqu2IY4zQkTmici8bdu2RTLJxhjjOxENBKqaoaqJuKFou8mRMzotAJqpakfcULXTQhxnoqp2VdWuCQlBi7iMMcYUUon0I1DV3SIyCzgbWBqwPjng+Sci8pyIxHtd8I0xUXTw4EE2bNhAWlpa/jubUqNy5co0btyYuLi4sN8TyVZDCcBBLwhUAc7ATT4RuE99YIuqqoh0w+VQQg4JbIwpORs2bKBGjRo0b96c0HMNmdJEVdmxYwcbNmygRYvcM6yGFskcQQPcdH6xuAv8VFWdISIjAVR1Am72pFEicgg3mNXlaj3cjCkV0tLSLAiUMSJCvXr1KGhdaiRbDS0GOgVZPyHg+TMUbpo8Y0wJsCBQ9hTmb2Y9i40xJlBmJmzb5h59wgKBMaZU2rFjB4mJiSQmJlK/fn0aNWp0+PWBAwfyfO+8efMYPXp0gT6vefPmbN++HZKTYe1a2OGf6kobfdQYUyrVq1ePhQsXAvDggw9SvXp17rwzex6eQ4cOUaFC8EtY165d6dq1a+E+eN8+97hrF/ikubrlCIwxZcawYcO4/fbbOf300xkzZgw//fQTJ598Mp06deLkk09m+fLlAMyaNYvzznMj1zz44IMMHz6c3r1707JlS8aPH5/3h2QFguRk1q5cSd++fenQoQN9+/Zl3bp1ALzzzju0a9eOjh070quXm6o6KSmJbt26kZiYSIcOHVixYkVkvoQIsByBMSZft90G3s15sUlMhKeeKvj7fv/9d2bOnElsbCzJycnMnj2bChUqMHPmTP7617/y3nvvHfGe3377jW+++Ya9e/fSunVrRo0aFbydvaoLBNWqwb593HzTTVx99dUMHTqUSZMmMXr0aKZNm8ZDDz3E559/TqNGjdi9ezcAEyZM4NZbb2XIkCEcOHCAjIyyM62yBQJjTJlyySWXEBsbC8CePXsYOnQoK1asQEQ4ePBg0Pece+65VKpUiUqVKnHUUUexZcsWGjdufOSO6emQkeGKhDIy+OGnn3h/xgwArrrqKu6++24ATjnlFIYNG8all17KoEGDAOjRowePPPIIGzZsYNCgQbRq1SoCZx8ZFgiMMfkqzJ17pFSrVu3w87/97W+cfvrpfPDBB6xZs4bevXsHfU+lSpUOP4+NjeXQoUPBD56amvUhUKeOyyEcPAhe7iGraeaECROYO3cuH3/8MYmJiSxcuJArrriC7t278/HHH3PWWWfx0ksv0adPn6KfcAmwOgJjTJm1Z88eGjVqBMCrr75a9AOmpkJMDFSuDHXrcnKHDkx55RUA3nzzTXr27AnAH3/8Qffu3XnooYeIj49n/fr1rFq1ipYtWzJ69GguuOACFi9eXPT0lBDLERhjyqy7776boUOH8sQTTxTL3XeHfv2IiYmBChW49NJLGX/ffQx/4AH+88ILJCQk8IoXFO666y5WrFiBqtK3b186duzIo48+yhtvvEFcXBz169dn7NixRU5PSSlzcxZ37dpVbWIaYyJv2bJlnHDCCdFORsnJzIRffoGjj4as+oONG93SoQMaV5EdO6BGDQgoaSqVgv3tRGS+qgZtU2tFQ8YYA7B/v6sTqFo1e12dOu5x1y5274Y1a+DPP6ORuMiyQGCMMZDdfyCgMpoqVaBKFXTnLrwuBOzaBaHqmssqCwTGGAMuEFSoABUr5lxfty6yLwU5eIBmzVymYXs5mzHFAoExxkB2R7Jco3fur+KKhxpX20VCgttl+3YXEMoLCwTGGJORAWlpOYuFcBf7NZsqkypVqaM7AdfXLC0NUlKikdDIsEBgjDHB6gdwd/779oHWroOk7oP0dOrUgdhYN1J1eWGBwBhTKvXu3ZvPP/88x7qnnnqKG2+8Mc/3ZDUv79+//+FxgAI9+OCDPPbYYzlX5goE06ZNY9GiX9mwwTUXffTlp5k5dy7s2kVsLNSr5yqNQ4xoEVLgYHiliQUCY0ypNHjwYKZMmZJj3ZQpUxg8eHBY7//kk0+oXbt2eB+2b5/rHOANaz1t2jS+++5XMjOhaVN4+J//5Iw+fWBndvGQavmZssACgTGmVLr44ouZMWMG6enpAKxZs4aNGzfSs2dPRo0aRdeuXWnbti0PPPBA0PcfnmgGeOSRR2jdujVnnHHG4aGqAV588UVOPPFEOp57LhfddRepqal8//33fPjhdP75z7u4+upENm78g2HDhvHu//0fpKby1aefcvLJnbjiivaMGjWctLT0w5/3wAMP0LlzZ9q3b89vv/0W9rlOnjyZ9u3b065dO8aMGQNARkYGw4YNo127drRv354nn3wSgPHjx9OmTRs6dOjA5ZdfXvAvNggbYsIYk78ojENdr149unXrxmeffcaAAQOYMmUKl112GSLCI488Qt26dcnIyKBv374sXryYDh06BD3O/PnzmTJlCr/88guHDh2ic+fOdOnSBYBBgwZx/dChsHgx97/5Ji+//DI33XQLvXpdQK9e53HbbRfjDXQK1aqRlp7OsGuv5atZs6hb9ziGDr2ap556nnvuuQ2A+Ph4FixYwHPPPcdjjz3GSy+9lO/XsHHjRsaMGcP8+fOpU6cO/fr1Y9q0aTRp0oQ///yTpUuXAhwu5nr00UdZvXo1lSpVClr0VRiWIzDGlFqBxUOBxUJTp06lc+fOdOrUiaSkJH799deQx5gzZw4XXnghVatWpWbNmlxwwQWHty1dupRTTzuN9pdfzpsffEBSUhL79rlGRHXrkh0EAOLiWJ6cTIv69TmuYUPq1oXzzx/KN9/MPrxL1pDUXbp0Yc2aNWGd488//0zv3r1JSEigQoUKDBkyhNmzZ9OyZUtWrVrFLbfcwmeffUbNmjUB6NChA0OGDOGNN94IOUNbQVmOwBiTvyiNQz1w4EBuv/12FixYwP79++ncuTOrV6/mscce4+eff6ZOnToMGzaMtLS0PI8jufoGZBk2bBjTJk6kY506vLp4MbNmzz48Z33QeWuOOsr1M1izhpg2bahZ01UYZ1UaZw13nedQ17mPGaJDQp06dVi0aBGff/45zz77LFOnTmXSpEl8/PHHzJ49m+nTp/Pwww+TlJRU5IBgOQJjTKlVvXp1evfuzfDhww/nBpKTk6lWrRq1atViy5YtfPrpp3keo1evXnzwwQfs37+fvXv38tFHHx3etnfvXhpUr87BuDjenDwZcGPPVatWg5SUvUcc6/i2bVmzdSsrV6yAP//k00//R6dOpxWp0rh79+58++23bN++nYyMDCZPnsxpp53G9u3byczM5KKLLuLhhx9mwYIFZGZmsn79ek4//XT+/e9/s3v3blKKoUODb3IE69bBt9/ChRdC9erRTo0xJlyDBw9m0KBBh4uIOnbsSKdOnWjbti0tW7bklFNOyfP9nTt35rLLLiMxMZFmzZpx6qmnHt728EMP0f3ii2nWpAntTzyRvXv3kpkJ/fpdzmOPXc8LL4zn3XffPbx/5cqVeeXVV7lk9GgOpadzYo8eDB06skB9Cr766qscs6O98847jBs3jtNPPx1VpX///gwYMIBFixZxzTXXkOllUcaNG0dGRgZXXnkle/bsQVX5y1/+En7LqDz4Zhjqd9+FSy6BRYsgRJ2SMSaAL4ahTkuDpUuhWTPXJhTXUWztWnedyD3s0GEZGZCUBDEx7KzfhlVrYjjuOPCK8aOu1AxDLSKVReQnEVkkIkki8vcg+4iIjBeRlSKyWEQ6Ryo9DRq4x02bIvUJxpgyJ0iP4qw6gpi8ro6xsdC8OaSlUSf1TypUcNeWMnZffVgk6wjSgT6q2hFIBM4WkZNy7XMO0MpbRgDPRyoxWYFg48ZIfYIxpszZt89d8atUObwqrEAA7vY/IQHZuoXm8Sns3Vt2bzQjFgjUyarFiPOW3PFyAPC6t++PQG0RaRCJ9FiOwJiCK2tFxwW2b5+biCagVVFWIAjR0Cinxo2hYkVq7VpNfN0MNm6EPXsik9RwFeZvFtFWQyISKyILga3Al6o6N9cujYD1Aa83eOtyH2eEiMwTkXnbCjnSU5UqULu2BQJjwlW5cmV27NhRfoNBZqabrD7XQHOZmS43EFYg8IqIJD2dZqyjahVl9WrwOkOXOFVlx44dVK5cuUDvi2irIVXNABJFpDbwgYi0U9WlAbsE+6qP+NWp6kRgIrjK4sKmp0EDKxoyJlyNGzdmw4YNFPbmq9Q7cMDVDKvmGFN6xw4XH5YtK8CxDh6E35ejldax7UA8O3fGUL9+mMGkmFWuXDlHq6RwlEjzUVXdLSKzgLOBwECwAWgS8LoxELFLdcOGliMwJlxxcXG0aNEi2smInIkT4YYbYNUqCDjPoUNdU/MwOwZne+EFuOkmGjXtQJvVMxh0U0OeeaZYUxwxkWw1lODlBBCRKsAZQO5RmKYDV3uth04C9qhqxC7VDRpYIDDGeLZudY+57p5TU3POXx+2G26Ajz6i9rYV/Fq9O98+u4S33ip6MktCJOsIGgDfiMhi4GdcHcEMERkpIiO9fT4BVgErgReB0AONF0eCvKKh8lrkaYwpgJQUN/R0rrEk9u8vZCAAOOccmDOHWjUz+TH2FCYP/5I8hkEqNSJWNKSqi4FOQdZPCHiuwE2RSkNuDRu6YsFdu9yAUsYYH0tJCTrMQGpqjtakBZeYiMydS8V+5/L+sv480Pt5Rvx0Hc2bF+GYEearsYasCakx5rA8AkGhcwRZGjcm7sc57Ovel39uu55ZbW5k8bwDRTxo5PgyEFjLIWNMRAMBQM2a1P5uBtuvuYth+59n/0m9+f6dP4vhwMXPV4GgYUP3aDkCY0yoQFCkOoLcKlQgftK/2f7cVNpnLqblpV345qE5xXTw4uOrQGBFQ8aYwyJVRxBE/KhLOPjdXA5UrkXPB/ow++LxparViq8CQbVqUKOGBQJjDJEvGsql1sltSVj9Ewvq96fXe7eysN2VZO45cs6DaPBVIABXPGR1BMaYEikayqVK/Vp0WfsB07r+g/a/TmFzw84kf13wYfWLm+8CgXUqM8YAQQNBRoYbJ6i4i4YCVagYw4Cf7uPD274hIzWNKn178Oet/84e7S4KLBAYY/wpSCDYv989RipHkEUEBj3Ziy1fLOaLKgNoNH4Mf7brF7XiCl8GAutdbIzPZWa6IahzBYLUVPcY6UCQpeuZdei25h2eOOFFai/7gb0tO5A+9UPX87UE+S4QNGzoon5ycrRTYoyJmqwrfpRyBIESjhJuXXIdL4+az8r0JlS6bKAb+qJKFahfH1q3hm7d4Mwz4ZVXIpIG30xenyWwCWmtWtFNizEmSrKGnQ6RI4hkHUEwsbEw+rnj+eysHxk95E1q799In/bJnNJuD3Gpe9xsN3v2ZE+tWcx8Gwg2boTjj49uWowxUZJPICjJHEGgswdUouua4dxzD5z+MjTZDP/9LwwcGNm5DXxZNARWYWyMr5XSQAAQHw8vvQTffedmVRw0CM4/H1avjtxn+i4QWO9iY0yoQBCNOoJQTjkFFiyAxx93E+W0bQvPPx+Zz/JdIKhRw/2RrVOZMT5WyuoIQqlQAW6/3U2bee65LrcQkc+JzGFLLxGbstIY3yvFRUPBNG4M77wTueP7LkcA1qnMGN8rA0VDJcm3gcCKhozxsTKWI4g0XwYCKxoyxufKSB1BSfFlIGjQwP0Osn4LxhifSUlxvbgqVcqxOisQVK4chTRFkW8DAViuwBjfyhpwLlcvrf37XW4gxmdXRp+drpPVqczqCYzxqRKcnaws8GUgsByBMT5XwrOTlXYWCIwx/mOBIAdfBoLatV1lkBUNGeNTUZimsjSLWCAQkSYi8o2ILBORJBG5Ncg+vUVkj4gs9JaxkUpPzs+1TmXG+JrVEeQQySEmDgF3qOoCEakBzBeRL1X111z7zVHV8yKYjqAsEBjjY1Y0lEPEcgSquklVF3jP9wLLgEaR+ryCatjQioaM8S0LBDmUSB2BiDQHOgFzg2zuISKLRORTEWkb4v0jRGSeiMzbtm1bsaTJcgTG+JjVEeQQ8UAgItWB94DbVDX3TMELgGaq2hF4GpgW7BiqOlFVu6pq14SEhGJJV4MGbua3rJ6ExhifULU6glwiGghEJA4XBN5U1fdzb1fVZFVN8Z5/AsSJSGRG3F6yBO6++/Cs9daE1BifSk+HjAwrGgoQyVZDArwMLFPVJ0LsU9/bDxHp5qVnR0QStGYN/Oc/kJQE2JSVxvhWiAHnwL9FQ5FsNXQKcBWwREQWeuv+CjQFUNUJwMXAKBE5BOwHLldVjUhq2nrVD0lJ0KOH5QiM8asQgUDVvzmCiAUCVf0OkHz2eQZ4JlJpyKF5c/cX9nIEWYHAWg4Z4zMhAkFamnu0OoLyLCYG2rSBpUsBqFcP4uIsR2CM79ikNEfwTyAAVzzk5Qisd7ExPmXTVB7BX4GgXTt35d+5E7ApK43xJZud7Aj+CgSBFcbYlJXG+JIVDR3B14HAioaM8aGsQFCtWo7VFgj8okkTqFEjRyDYudP1LzHG+ITVERzBX4FAxOUKvJZD1qnMGB/KCgS5rvhWR+AnAS2HrFOZMT6UkuKCQGxsjtVWNOQn7drBtm2wdasFAmP8KI8B58ACgT8EVBhnFQ1ZE1JjfCSPIajBAoE/BASC+HioUMFyBMb4Sj45Aqsj8IMGDaBOHUhKIiYGjj7aAoExvmKB4Aj+CwRBWg5Z0ZAxPpJH0VDFiq6UwG/8Fwggu+WQqnUqM8ZvbHayI/gzELRrB7t2webNFgiM8RubuP4I/gwEWRXGS5fSsKFrTXrgQHSTZIwpIRYIjuDvQJCUdLgvwZYt0UuOMaYE5VFHYIHAT446ChIScgQCKx4yxgcOHnSDi1kdQQ7+DARwuOWQTVlpjI/s2+cerWgoB38Hgl9/pVlTBWDVqiinxxgTeSFGHgULBP7Urh0kJxOftoGGDWHRomgnyBgTcXkEAqsj8KOAlkMdO8LChVFNjTGmJOSTI7A6Ar8JaDmUmAjLllkTUmPKPSsaCsq/gaBuXTfuUFISHTu6xgS//hrtRBljIsoCQVBhBQIRqSYiMd7z40TkAhGJy+c9TUTkGxFZJiJJInJrkH1ERMaLyEoRWSwinQt3GoXktRxKTHQvrZ7AmHIuRCBQtTqCcMwGKotII+Ar4Brg1Xzecwi4Q1VPAE4CbhKRNrn2OQdo5S0jgOfDTE/x8FoOHdsyk6pVrZ7AmHIvRCA4eBAyMqyOID+iqqnAIOBpVb0QyH1Rz0FVN6nqAu/5XmAZ0CjXbgOA19X5EagtIg0KdAZF0a4dpKYSu2Et7dtbIDCm3AsRCPw8OxkUIBCISA9gCPCxty7swVpFpDnQCZiba1MjYH3A6w0cGSwiJ6DlUGKiKxpSLbFPN8aUtKxAUK1ajtV+np0Mwg8EtwH3Ah+oapKItAS+CeeNIlIdeA+4TVWTc28O8pYjLsUiMkJE5onIvG3btoWZ5DC08TI1XoXxrl2wfn3ebzHGlGEpKW7SgYoVc6z286Q0EGYgUNVvVfUCVf2XV2m8XVVH5/c+r0L5PeBNVX0/yC4bgCYBrxsDRwz2oKoTVbWrqnZNSEgIJ8nhqVULmjQ53IQUrMLYmHLNJq4PKtxWQ2+JSE0RqQb8CiwXkbvyeY8ALwPLVPWJELtNB672Wg+dBOxR1ZId/s1rOdS+vZu8zOoJjCnHLBAEFW7RUBuvWGcg8AnQFLgqn/ec4u3TR0QWekt/ERkpIiO9fT4BVgErgReBGwt6AkXWti389hvVq2Rw7LEWCIwp1/IYghr8GwjCrfCN84p5BgLPqOpBEcmzWlVVvyN4HUDgPgrcFGYaIqNdO0hLg1WrSExsxYIFUU2NMSaSbOL6oMLNEbwArAGqAbNFpBmQu+K3bMpqObRkCYmJ8McfkFw+zswYk5sVDQUVbmXxeFVtpKr9vTb/a4HTI5y2ktG+vWtK9sUXdOzoVi1ZEt0kGWMixAJBUOFWFtcSkSeymnCKyOO43EHZV7kynHMOfPghiR0yAasnMKbcsjqCoMItGpoE7AUu9ZZk4JVIJarEXXghbN5Mw/VzqVfPAoEx5ZbVEQQVbmXxMap6UcDrv4vIwgikJzr694cKFZAPp5GY2MP6EhhTXlnRUFDh5gj2i0jPrBcicgqwPzJJioLataFPH/jgAxI7KkuWwKFD0U6UMaZYZWa6OYtDFA3FxkJcnmMql1/hBoKRwLMiskZE1gDPADdELFXRMHAgrFhBr4RlpKXBihXRTpAxplhl3fbnMReB5NngvfwKt9XQIlXtCHQAOqhqJ6BPRFNW0gYMAKDbnx8AVk9gTLlj01SGVKAZylQ1OWDguNsjkJ7oadgQTjqJo36YRsWKFgiMKXdsdrKQijJVZfnLRA0cSMz8efRptd4qjI0pb/IIBH6enQyKFgjK38j9F14IwJXVp1mOwJjyxoqGQsozEIjIXhFJDrLsBRqWUBpLznHHwQkn0GvnNLZsgc2bo50gY0yxsaKhkPIMBKpaQ1VrBllqqGrYM5SVKRdeSOM/vqUuO6x4yJjyxAJBSEUpGiqfLrwQyczgXD624iFjyhOrIwjJAkFuXbpA48YMqfKB5QiMKU+sjiAkCwS5icDAgfQ+8Dm/LUiNdmqMMcXFioZCskAQzMCBVMrYT/Pfvzg8KqExpoxLSYGYGDficC4WCMyRevXiQPU6XKDTWLo02okxxhSLrAHngowjYXUE5khxcaSfcR7n8xGL5tvoc8aUCyFGHj10CA4csDoCE0S1Ky+kHjvZPX12tJNijCkONilNSBYIQog55yzSY6tQ7+t3OHgw2qkxxhSZBYKQLBCEUrUqW0+9mIvS3+Tr6SnRTo0xpqhsUpqQLBDk4egHRlKTvaz/z5RoJ8UYU1Q2TWVIFgjyUPG0Hmyo057OP084/GMxxpRRliMIyQJBXkRIuXIknTPn8/1/f452aowxRWF1BCFFLBCIyCQR2SoiQVvii0hvEdkjIgu9ZWyk0lIUrf5+JfukGrwwIdpJMcYUhRUNhRTJHMGrwNn57DNHVRO95aEIpqXQYuvUZGHbIZy8djJ71u6OdnKMMYWhakVDeYhYIFDV2cDOSB2/JNW4cyRV2c+y+/4X7aQYYwojPR0yMiwQhBDtOoIeIrJIRD4VkbZRTktI7a/uxMJK3WgwbYK7szDGlC35DEENFgiiZQHQTFU7Ak8D00LtKCIjRGSeiMzbtm1bSaUv4PNh5RkjabbvV3ZNn1Pin2+MKaJ8Rh4FqyOIClVNVtUU7/knQJyIxIfYd6KqdlXVrgkJCSWazizHj72MXdRm28NWaWxMmRNGILAcQRSISH0RNwygiHTz0rIjWunJT7tuVZlRdygtFrwLW7dGOznGmILYt8895hEIgoxO7RuRbD46GfgBaC0iG0TkWhEZKSIjvV0uBpaKyCJgPHC5aukugN935Q3E6UF2PfVqtJNijCmIMKapDDI6tW9EbAJ6VR2cz/ZngGci9fmRcOboE5g1/jQ6vvAC/ONON8mFMab0s2kq82RXsgI45hiYecxI6uxcBV9+Ge3kGGPCZdNU5skCQQEdNXIQW0lg398fg8zMaCfHGBOOMIqG/MwCQQFdfEVFHmYs1X6YCXfeGe3kGGPCYTmCPFkgKKCGDeHX02/ilRqj4ckn3WKMKd2yAkGQK77VEVggKJRbRgvX7X2C9d0ugttvh6lTo50kY0xeUlJcEIiNPWKT5QgsEBTKBRfAMa1iuezgG2jPnnDVVfDtt9FOljEmlBADzoHVEYAFgkKJiYE77oAffqnM/931IbRsCQMHQlJStJNmjAkmj0BgRUMWCArt6qshIQHGvVAXPv3UdUs85xz4889oJ80Yk1s+gcByBKZQqlSBW26BTz6BpH3NXTDYtQvOPRfS0qKdPGNMIAsEebJAUASjRrmA8PjjQGIiTJkCixbBww9HO2nGmEBWR5AnCwRFEB8Pw4fDG2/Axo243MCwYfCvf8HChVFOnTHmsBCBIDPTBQKrIzBF8pe/uImPnn7aW/H449kR4tChqKbNGOMJEQiySnEtR2CK5JhjYNAgeP552LsXqFsXnn0WfvkFHnss2skzxoDNV5wPCwTF4M47Yc8eePllb8VFF7nlwQdh+fJoJs0YAyEDgU1T6VggKAbdu8Opp7rRJg4e9FY+84wreLzuOhuczphoOnTIlQHZNJUhWSAoJnfdBevWwTvveCvq13eR4bvvYEKQ6S337IHx4+Gkk+CVV0o0rcb4Shizk1mOwBSLc8+F44+Hf//bVR4DMHQo9OsHY8bA2rVuXVIS3HgjNGoEt94Kq1e7iuXHH49a2o0p1/IZghosEFggKCYxMTB2rOtGcM893koReOEFUIXBg6FPH2jXDiZNgksugZ9/hvXr3fM774T773f7GhMJN98M118fcKfiEzZxfb4iNlWlHw0e7EqCHnsMOnaEK68EmjeHRx913ZCbNXPPr73WNTHNMnky1KwJjzwCu3e7IiObBtMUp4ULXWu2LBMn+meS3jACgd/rCCwQFLOnnoJff3V1xK1bw4knAjfdBKedBm3aBB0Gl9hYePFFqFPHRZHdu129QVxcCafelFvjxkGNGq4Y8r//dQNl/fOf0U5VybAcQb4sEBSzuDhXYdy1qxuQdN48aNBAoH37vN8o4ioY6taFv/4VkpPh7bftVsUU3e+/ux/lmDHu4p+W5gJDQoLrEVneWR1Bvqz8IQLi4+HDD92N/aBBkJ4e5htF4N574bnnYMYMaNHCDWj05ZcB7VKNKaBHH4VKleC229xv7Nln4eKL3aRKr78e7dRFnhUN5csCQYR07Oj+x3780V3LC1QHPGoUfPaZ65zw+uuu5dHRR7tWSB9+mH0bY0x+1q2D//3PVRIffbRbFxvrBsjq29cVFc2YEd00RpoVDeXLAkEEXXSRa0n0yisBYxGFq18/l53fvh2mTYPzz4fp01150zHHlP9/XlM8/vMf93jnnTnXV6oEH3zgRs295BLXyqE4TJ7sKslKE8sR5MsCQYQ98IC7dt9+O3z9dSEOUKUKDBgAr70GW7e6eQ/i411gGDbMlT8ZE8yWLfDSS24WpaZNj9xeo4b7PTVt6n5PK1cW7fM++giuuMKVhx44ULRjFaesQFCt2hGb9u93MTFYGw4/iVggEJFJIrJVRJaG2C4iMl5EVorIYhHpHKm0RFNMjCvdad0aLrvM5dQLLS4Ozj7b9T+47z6XvW/Xzv0zG5Pbk0+6C/KYMaH3SUhwv5+YGHfHknXRLKjt213xU4MGbnytAmeBIyglBSpWdEsuNk2lE8kcwavA2XlsPwdo5S0jgOcjmJaoqlHD5cIPHHA3S0Uu4q9UCf7xD1cBUasW9O/v+ibs2VMs6TXlwK5drtHBJZfAccflvW/Llq6F2rJlrh6qoJ0aVWHkSNi509Vt9e8PDz3kciSlgc1Olq+IBQJVnQ3szGOXAcDr6vwI1BaRBpFKT7Qdd5yrs5s/340wUSwdiLt2hQULXEujV191H3L99fDee6GDQnq6K6O6917o2dN1dPvjj2JIjClVnnnGjYt+773h7X/GGa4+4f33C96/4K233G/u4YehQweXE9m/3zWDLg1sdrL8qWrEFqA5sDTEthlAz4DXXwFdQ+w7ApgHzGvatKmWZWPHqoLqs88W84HnzlW96CLVmjXdB1SooNqrl+q4caqzZqk++aTqOeeoVq2avf3EE1Xj4lRFVAcNUv3uO9XMzGJOWJSkpqr+/rvqoUPh7b9xo+q556qefrpqcnJk0xZpe/eq1q2ret55BXtfZqbqkCHu9/DRR+G9Z8MG1dq1VU8+Oed3feed7jg//1ywNBS3n35y6Tv11KCbBw5U7dChhNMUJcA8DXWtDrWhOJZ8AsHHQQJBl/yO2aVLl8h8SyUkI8NdbypUcNfdYnfggOq336ree69qYqL7E2ctrVur3nKL+yfPutht3Kj617+q1qnj9uneXXXqVNWDByOQuAhITVWdM0d14kTV2293wa5FC3cRAtXOnVV//DHvY3zyiWpCgmqVKqqxsS4Y7N9fMumPhMcfd+f+/fcFf29qqvvOatZU/e23vPfNzFTt18/dXKxYkXPbnj2qRx+t2qOH+9FHww8/uPNo0UJ19eqgu/Tr537yflBaA8ELwOCA18uBBvkds6wHAlXVXbtUjz1WtX591T//jPCHbdyo+uGHqmvW5L1fSorLphx7rPtZVKyo2qaNu2W6+27Vl192F9wdOyKc4Hzs36/6zTcua9Wrl0tnVqCrUsUFv8svV33wQZcLatjQbbvuOtVt23IeKy1N9S9/cdvbt1dNSlJ94w0XRM4/3wXVsmbmTNX4eBfMCmvtWhcYW7dW3b079H7PPee+u+eeC7590iS3/fXXg2+PpDlzVGvUcL/ndetC7tazZ9G+qrKktAaCc4FPAQFOAn4K55jlIRCoqi5ZolqtmstRp6dHOzUBDh1SnT5ddcwYFwTatMl5sQX3zzVkiOr48e5uOy0tcunJzFT99VfVRx9V7d1btVIll4aYGNUuXVwRxPTp7o4v2J1ncrLbp0IFV1wyYYI7x+XLVTt1cse6+eacOYBnn3Xrr7gienezBbVnj+qIES7dxx2nunRp0Y43a5bLHZ11lupnnx35/a5Y4XICZ50VujgxI8MVPzZoULLFbbNmuX+u1q1d0VUeunRxOXQ/iEogACYDm4CDwAbgWmAkMNLbLsCzwB/AklD1A7mX8hIIVFXfftv9Bfr3d8W6pdbBg6orV7oilHHjXIBo0CA7MFSs6C6q/fqpXnaZ6g03qN5zj+q//qX64ouqH3/sIt+ePeF93oED7q7/L39RPeaY7M9JTHTFP9Onu2xVQSxd6gIJqHbs6C4U9eq53FIw48a5fUeOzL/eJDNTdfNmFxSnTHFB69ZbXdFESfj0U9XGjV1wvPNOV7xTHJ57LruIDVQrV3Y5p4svVm3XzpW953Oh1R9/dO+9557iSVN+Zs50OcM2bVQ3bcp39xNOUL3kkhJIVykQtRxBJJbyFAhU3Q1qTIy7xuX3P1WqZGaqrl+v+u67qnfdpXr22ardurm70YQEdwcemIvIWmrWdBeRc85RvfBCVwRzzjmqZ57p8ug9e2bXV1Ss6LY9/7z7rOJI81tvueKiPn3y/8LHjDnyIpaZ6e6GJ01SveYad8GpUuXI84yLc3fU48ZFLlexc6fqsGHu89q0yb8upDC2bHF1ThMnqt5xh6uAbtXKBYUpU8I7xtVXu79l7nqE4vbxx9nBasuWsN7SrJlLnh/kFQjEbS87unbtqvPmzYt2MorVp5/CpZe6LgEff+zGKSrzVN0UgTt3woYNbgKedetyPh48CBUq5FxiY90cDuef74bZCNHsr0gyM93ga/mNx6/q2vpOmODG5ElOdkMxbN7sttetCyef7JrtNm+evTRr5t47YgRMnQpnnul6FdavX/C0qro+AatXH7nMm+e2jRnjxjKpVKngxy8s1fDnM9i0yX1HlSu77yc+HurVc4/x8W5wxQEDCv+3XrvWzQY1ZYobMuPLL3PO95GHo45yQ8E8X257MWUTkfmq2jXYNhuGuhQ45xx3fTn3XNe0/513XAfiMk3E/WNXrx58eINoCnfSn6yROvftc7PKNW3qBmo79VT3hzrhhLyPNWWKCwKjR7vo/r//ueCW27ZtrnPgsmWwcaO7cG7cmP08dw/EOnXcxbNvXzdZdpcu4Z97cSnIpDYNGsC777rz37HD9UL+7Tf3fO9et0+1aq7r/fDhLriGc/zkZDey6hNPZE8RePfdQYeSCMX6ETiWIyhF/vwTzjsPlixx158bboh2isxhu3dD7dqFe29SkrvIJSW5u/dLL3UX/h9+cEtgh77q1aFhQ3fxbNgwe2nRInupVas4zqh0OHDADZnyyiuud3NKiss9DB8OQ4a47yH3QEAZGS4w33+/G3/ryitdJ7gmTQr00aouE3rvva6jfnmXV47AAkEps3cvXH45fPKJGyts7Fg32Kgp41JT3SQwEydmrzv6aOjRI3vp2NFNWepXKSku5zBpEsyZk72+UiU3IFDVqm5JS3PFjaec4noxn3hioT4uPd2VVj3ySOnpBB1JFgjKmEOH3M3OU0+5YvQrrnA/1BNOiHbKTJF99ZW7i+3Rw9Ul+GXe4IL6/XdXYZac7ILo/v3uMTXV/VNceqmbXKcI39+uXa6a58kn3Zw95Z3VEZQxFSq4os9bb4XHH3cVWW++6Sq17r+/nFQm+1XfvtFOQdlw3HH5D5ZXRDZNZTabj6AUa9DAzWW/dq3LEXzxhWsUcf75xTePiDF+ZZPSZLNAUAbEx7vKrLVr3ei+P/zgGq6ccoqbuTIzM9opNGVNaiosWuRatz78sBux2m9smspsVjRUhtSuDX/7G9xxh6tPe/xxN5fI8ce7VoRDhpRsU3JTtrz/vusSsXx58AmS6tVzjZv8woqGslmOoAyqWhVuvhlWrHBDwVeq5Oalad7c9atZtizaKTSlTWoqXHONq4Pt2RP+/nfXWnPhQjd1Rffubm6ZDRuindKSYzmCbBYIyrAKFWDwYPjlF/j8c9eK7rHHoE0bOOkkd/e3a1e0U2lKg2nTXAOcV191DQ/GjnUNb7JarP7vf64xztCh/ilqtDqCbBYIygER12F1+nTXKe3xx11n2FGjXIXzZZe5baVpPnFTsl55xeUYe/UKvr1VK9dc+euv3aMfWI4gmwWCcuboo+H222HxYjct5ogRrun6gAFuqJvrr3f/7BkZ0U6pKSnr1rnfwLBheY+Ice217ndy773u91PeWR1BNgsE5ZQIdO4M48e74Wo+/tiNZTRlimvK3qSJ60Tz2mtu0Lt589wFI/ewNqbse/11N5zC1VfnvZ8IvPiiG8poyBDXgbc8sxxBNms15ANxcdC/v1tSU11QmDzZdVQLVlxUvXr2AJF167ol6/mxx8KgQVCjRsmfhyk4VVcvcPrpbpii/CQkuGKk/v1d35Unnoh4EqNm/Xr3WIAx6sotG2LCx/bvd7mFrVvdAJhbt2YvO3a4EaQDH3ftchWJ1aq5isZrrw1/oEgTHbNnw2mnuVzBVVeF/76bb3YDH375JZxxRuTSFy1btrh6kV69YMaMaKemZNhYQ6ZYZGbC3Lnw8svZA0W2bu0Girz66sINt28ia/hwN47bpk0Fu/NNTXWjWycnw7ffupxgeXL99S6ntHSp+w37QV6BwOoITNhiYtxYaS+95C4skya5IqQxY6BRI5c7+Mc/YMEC/zRBLM1SUlzP4UsvLXjxR9WqrvgwLQ26dXMNDMqLhQvdzcwtt/gnCOTHAoEplOrVXQel775zHdjuv9+Nmvq3v7k7yUaN3N3o1KluGP6UlGin2H/efdc1I77mmsK9PzERfvrJNUHu188VFZWxAoQjqLpGEnXrut+qcaxoyBSrLVtc57ZPPnGPu3dnb6tb1428nLW0beuCRrt2ULFiyaVx82YXnNasceM3rVmT/bxuXdf/4sory35rkt693SRny5cXrR4nOdm1Ipoxw02WNH58yf69itN777nRq597zv2d/cTqCExUHDrkej3/8Ye7yAYua9a4u1VwF5UOHVxQ6NLFNV/MmqUxa9bGTZvc8dq3d3eqiYnQqZOrlwh3VsP334c33nDFHFk/+5gYaNw4e6rhJUtc0UGdOq4c+cYb3fqiyshwnfqefdYFm7FjXQCMlFWr3IRGxTXpSkYG3Hcf/OtfrvL53XfDnha41EhLc73uq1Vzv8sKPmszmVcgCDqjfWleunTpoqbsy8xUXblS9e23Ve++W7VPH9XatVXdJdotcXGqTZqoduumOnCgW1q2zLnPUUepnnGG6g03qI4bpzpliuqPP6pu3qyanq46Y4bq5ZerVqni9m/ZUnXsWNWvvlJdtUr1wIEj0zVnjurFF6vGxqrGxKgOGqT67bduW0GlpqpOmKDaqpX7/GbNVGvWVBVRHTxY9fffi+XrPMLf/uY+Y/364j3uG2+oVqqk2ry56rRpqocOFe/xI2ncOPc3+PLLaKckOoB5GuK6GvULe0EXCwTlV1ZwWLRIdetW1YyM4Pvt3q06e7bqf/+res01ql27qtarlzNAgLuIg9t2442q339fsIv52rWq99yjWreuO07PnqqffRbeMbZvV33oIdWEBPferl1d0Dt40G275x7VqlVdsBk+XHX16vDTlZ+MDNWmTVX79Su+YwaaO1e1RQt3Xsceq/rMM6opKaH3X71a9eWXVZ97TvWXX9x3UNI2bVKtXl31ggtK/rNLCwsExheSk1WXLFH96CPV8ePdxXb6dJczKIp9+9zFrkkT9x9z4omqH36YMyBkZqouX6765JMuh1Kxotu3f3/Vb74JHjw2b1a97TZ3hx0Xp3rTTW5dUc2c6T578uSiHyuUgwdVp05V7d7dfVadOu773rDBBfG331a9/vojc3DgLsh9+7pcy6efusAeacOHu+84UjmwssACgTHFID1ddeLE7Lvhjh1Vn39e9ZZbVI85JvtC16aN6h13uKAUjnXrVEeMcLmDatVUH3jABbXCOHRI9bLLVGvVcsVSJeH7711RWkyMO4es76FmTXcH/t//qi5d6ori3nzTBbxOnbJzbFWquO9ry5bIpG/+fFdMdscdkTl+WRG1QACcDSwHVgL3BNneG9gDLPSWsfkd0wKBibaDB1Vfe021devsC9l557mij6IU8Sxf7i6o4IqUnn46dG4mM9PlHmbOVH3iCVdE1qWLauXK7v033VT4dBTWqlWq992n+sgjrp4mvyKgvXtdXc3QoS4oVK3q6ou2bSu+NH3+uWqDBu77LImcR2mWVyCIWKshEYkFfgfOBDYAPwODVfXXgH16A3eq6nnhHtdaDZnSIiPD9Uw97rjiHdN+7lzXSe/bb13Ln1tvdS2sspq4Zi1Zg6aBG3W2fXvX+qpDBzf0eOXKxZemSPv9dzcN61tvuWa7o0e7mfjq1Svc8dLS3Hc4frxrKTR5svte/CwqzUdFpAfwoKqe5b2+F0BVxwXs0xsLBMYcQRU++8xdzJYscevi43P2w2je3F3k2rd3gaA8WLbMBYS333bBtVu3nEvjxvk3F168GK64wvUVueUW1+TVJp+JXiC4GDhbVa/zXl8FdFfVmwP26Q28h8sxbMQFhaQgxxoBjABo2rRpl7Vr10YkzcaUNhkZLidQv76/RslMSoIXXnC5o4ULs0fJrV/fzcR3/PFuNNUWLaBlSxcY4+LcpDr33uv6arzyCpx9djTPonTJKxBEsktFsLidO+osAJqpaoqI9AemAa2OeJPqRGAiuBxBMafTmFIrNtYVD/lN27auWAcgPd3d5f/0k1t+/tn1Wg8cQl3EdQLcudNNrvPii25IbROeSAaCDUCTgNeNcXf9h6lqcsDzT0TkORGJV9XtEUyXMaYMqVTJ5QJOPBFuusmty8x0vc1Xr85e1qxxw0oPHWpDoxdUJAPBz0ArEWkB/AlcDlwRuIOI1Ae2qKqKSDfcIHg7IpgmY0w5EBPjBjZs1Ah69ox2asq+iAUCVT0kIjcDnwOxwCRVTRKRkd72CcDFwCgROQTsBy7XSFVaGGOMCcoGnTPGGB+wiWmMMcaEZIHAGGN8zgKBMcb4nAUCY4zxOQsExhjjcxYIjDHG58pc81ER2QYUdrCheMCvvZb9eu523v5i5x1aM1UNOvBGmQsERSEi80K1oy3v/Hrudt7+YuddOFY0ZIwxPmeBwBhjfM5vgWBitBMQRX49dztvf7HzLgRf1REYY4w5kt9yBMYYY3KxQGCMMT7nm0AgImeLyHIRWSki90Q7PZEiIpNEZKuILA1YV1dEvhSRFd5jnWimMRJEpImIfCMiy0QkSURu9daX63MXkcoi8pOILPLO++/e+nJ93llEJFZEfhGRGd7rcn/eIrJGRJaIyEIRmeetK9J5+yIQiEgs8CxwDtAGGCwibaKbqoh5Fcg9Zfc9wFeq2gr4yntd3hwC7lDVE4CTgJu8v3F5P/d0oI+qdgQSgbNF5CTK/3lnuRVYFvDaL+d9uqomBvQdKNJ5+yIQAN2Alaq6SlUPAFOAAVFOU0So6mxgZ67VA4DXvOevAQNLMk0lQVU3qeoC7/le3MWhEeX83NVJ8V7GeYtSzs8bQEQaA+cCLwWsLvfnHUKRztsvgaARsD7g9QZvnV8craqbwF0wgaOinJ6IEpHmQCdgLj44d694ZCGwFfhSVX1x3sBTwN1AZsA6P5y3Al+IyHwRGeGtK9J5R3Ly+tJEgqyzdrPlkIhUB94DblPVZJFgf/ryRVUzgEQRqQ18ICLtopykiBOR84CtqjpfRHpHOTkl7RRV3SgiRwFfishvRT2gX3IEG4AmAa8bAxujlJZo2CIiDQC8x61RTk9EiEgcLgi8qarve6t9ce4AqrobmIWrIyrv530KcIGIrMEV9fYRkTco/+eNqm70HrcCH+CKvot03n4JBD8DrUSkhYhUBC4Hpkc5TSVpOjDUez4U+DCKaYkIcbf+LwPLVPWJgE3l+txFJMHLCSAiVYAzgN8o5+etqveqamNVbY77f/5aVa+knJ+3iFQTkRpZz4F+wFKKeN6+6VksIv1xZYqxwCRVfSS6KYoMEZkM9MYNS7sFeACYBkwFmgLrgEtUNXeFcpkmIj2BOcASssuM/4qrJyi35y4iHXCVg7G4G7upqvqQiNSjHJ93IK9o6E5VPa+8n7eItMTlAsAV7b+lqo8U9bx9EwiMMcYE55eiIWOMMSFYIDDGGJ+zQGCMMT5ngcAYY3zOAoExxvicBQJjPCKS4Y3omLUU24BlItI8cERYY0oTvwwxYUw49qtqYrQTYUxJsxyBMfnwxn//lzfu/08icqy3vpmIfCUii73Hpt76o0XkA2+OgEUicrJ3qFgRedGbN+ALrycwIjJaRH71jjMlSqdpfMwCgTHZquQqGrosYFuyqnYDnsH1UMd7/rqqdgDeBMZ768cD33pzBHQGkrz1rYBnVbUtsBu4yFt/D9DJO87IyJyaMaFZz2JjPCKSoqrVg6xfg5v8ZZU3sN1mVa0nItuBBqp60Fu/SVXjRWQb0FhV0wOO0Rw3RHQr7/UYIE5V/yEinwEpuKFApgXML2BMibAcgTHh0RDPQ+0TTHrA8wyy6+jOxc2g1wWYLyJWd2dKlAUCY8JzWcDjD97z73EjXwIMAb7znn8FjILDk8bUDHVQEYkBmqjqN7hJVmoDR+RKjIkku/MwJlsVb6avLJ+palYT0koiMhd38zTYWzcamCQidwHbgGu89bcCE0XkWtyd/yhgU4jPjAXeEJFauAmUnvTmFTCmxFgdgTH58OoIuqrq9minxZhIsKIhY4zxOcsRGGOMz1mOwBhjfM4CgTHG+JwFAmOM8TkLBMYY43MWCIwxxuf+Hwg0i7ehiBLgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "best_model,max_accuracy = fit_model(model,num_epochs,train_dataloader,validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f3da8-346e-4a61-86ed-b478d3650e1b",
   "metadata": {},
   "source": [
    "We performed multiple experiments on the training and validation dataset. The model mentioned in the previous cell, is the last experiment we performed on LSTM.\n",
    "\n",
    "Other experiments performed on GRU are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f69f6-9301-4afd-a19f-ec2f5f4ed731",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100 #10 previous stock values\n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "output_dim = 50\n",
    "\n",
    "random_seed = 2\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim,out_dim=output_dim, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8edfef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model,'ai_gru_dp_2_bs_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ad564-2ad9-4e04-a3f1-8535695d0236",
   "metadata": {},
   "source": [
    "# Testing the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a84905-36ee-4c72-9362-44030d9c0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('ai_gru_dp_2_bs_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ee4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ace7afa-10e4-495a-8950-62287a465dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10736\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "predicted_results = []\n",
    "y_true = []\n",
    "for batch_idx,(feature_data,labels) in enumerate(validation_dataloader):\n",
    "    feature_data = feature_data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = best_model(feature_data)\n",
    "    _,predicted = torch.max(output.data,1)\n",
    "    predicted_results = predicted_results+list(predicted.cpu().detach().numpy())\n",
    "    y_true +=  list(labels.cpu().detach().numpy())\n",
    "    \n",
    "print(len(predicted_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b5114ee-3b4e-4572-9dc0-67bfaeba3a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81       165\n",
      "           1       0.71      0.39      0.50        75\n",
      "           2       0.64      0.24      0.35        38\n",
      "           3       0.71      0.62      0.66       317\n",
      "           5       0.57      0.40      0.47        70\n",
      "           7       0.90      0.84      0.87      1353\n",
      "           8       0.74      0.62      0.67       214\n",
      "           9       0.77      0.79      0.78       159\n",
      "          10       0.77      0.49      0.60        73\n",
      "          11       0.80      0.70      0.75       143\n",
      "          12       0.73      0.65      0.69        88\n",
      "          13       0.86      0.89      0.88       512\n",
      "          14       0.82      0.81      0.81       261\n",
      "          15       1.00      0.17      0.29        41\n",
      "          16       0.62      0.58      0.60       135\n",
      "          17       0.67      0.85      0.75       213\n",
      "          18       0.84      0.85      0.85       325\n",
      "          19       0.93      0.78      0.85       113\n",
      "          20       0.92      0.81      0.86       469\n",
      "          21       0.61      0.81      0.69       114\n",
      "          22       0.62      0.43      0.51        90\n",
      "          23       0.90      0.41      0.57        63\n",
      "          24       0.50      0.78      0.61       220\n",
      "          25       0.95      0.99      0.97       884\n",
      "          26       0.80      0.64      0.71        70\n",
      "          27       0.94      0.76      0.84       189\n",
      "          28       0.71      0.78      0.74       144\n",
      "          29       0.85      0.77      0.81       204\n",
      "          31       0.76      0.82      0.79       146\n",
      "          32       0.91      0.88      0.90       338\n",
      "          33       0.86      0.87      0.86       105\n",
      "          34       0.54      0.53      0.53       121\n",
      "          35       0.86      0.83      0.84       136\n",
      "          36       0.70      0.85      0.77       495\n",
      "          37       0.61      0.75      0.67       220\n",
      "          38       0.91      0.82      0.86       468\n",
      "          39       0.48      0.75      0.58        88\n",
      "          40       0.77      0.63      0.69       179\n",
      "          41       0.91      0.89      0.90       192\n",
      "          42       0.88      0.81      0.84       277\n",
      "          43       0.71      0.58      0.64        81\n",
      "          44       0.75      0.85      0.79       476\n",
      "          45       0.81      0.63      0.71       129\n",
      "          47       0.78      0.85      0.81       366\n",
      "          49       0.70      0.86      0.77       177\n",
      "\n",
      "    accuracy                           0.80     10736\n",
      "   macro avg       0.77      0.71      0.72     10736\n",
      "weighted avg       0.81      0.80      0.80     10736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, predicted_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c525f5a-47e4-47b6-a98d-c4061f41c320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
